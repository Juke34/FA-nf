params {
 // Protein fasta input
 proteinFile = "${baseDir}/dataset/P.vulgaris.proteins.fa"
 // GFF input
 gffFile = "${baseDir}/dataset/P.vulgaris.gff3"
 // Whether to run pipeline in debug mode or not
 debug = true
 // Whether to check and clean GFF input file
 gffclean = true
 // Whether to generate stats from GFF input file
 gffstats = true
 // Processing sizes below
 // Number of protein sequences per chunk (used as fallback)
 chunkSize = 25
 // Number of protein sequences per chunk when using BLAST (or DIAMOND)
 // You can normally use a far higher number if using DIAMOND
 chunkBlastSize = 50
 // Number of protein sequences per chunk when using InterProScan
 chunkIPSSize = 25
 // Number of protein sequences per chunk when using KofamKOALA
 chunkKoalaSize = 50
 // Number of protein sequences per chunk when submitting to web processes (CD-Search for now)
 chunkWebSize = 100
 // Number of chunks to be used when running in debug mode (e.g., for facllback processes this would be 5*25=125 protein sequences)
 debugSize = 5
 evalue = "0.00001"
 diamond = true
 blastDbPath = "/nfs/db/ncbi/201908/blastdb/db/nr"
 // Instance from where to retrieve GO mappings. You can set up your own at: https://github.com/toniher/gogoAPI
 gogourl = "http://gogo.test.crg.eu/api"
 // Maximum number of hits to consider (up to 30 by default))
 // gogohits = 30
 // Modes of retrieval from BLAST matches (common, most, all)
 blastAnnotMode = "common"
 speciesName = "P.vulgaris"
 // Pre-downloaded OBO file with GO descriptions. Otherwise pipeline will download it
 oboFile = "${baseDir}/dataset/gene_ontology_ext.obo"
 kegg_species = "hsa, dme, cel, ath, sce, cho, eco, nme, hpy, rpr, bsu, lla, cac, mge, mtu, ctr, bbu, syn, bth, dra, aae, mja, ape, aly, cit, tcc, gmx, fve, csv, vvi, sly, osa, olu, ota, mis, cme, gsl"
 kolist = "/nfs/db/kegg/ko_list"
 koprofiles = "/nfs/db/kegg/profiles"
 koentries = ""
 ipscantmp = "${baseDir}/tmp/"
 dbEngine = "MySQL"
 dbname = "Pvulgaris"
 dbuser = "test"
 dbpass = "test"
 dbport = 12345
 mysqldata = "${baseDir}/mysql/"
 mysqllog = "${baseDir}/tmp"
 mysqlimg = "docker://library/mariadb:10.3"
 // Where results are stored
 resultPath = "${baseDir}/results/"
 // Where log files are stored
 stdoutLog = "${baseDir}/logs/functional_annotation.stdout"
 stderrLog = "${baseDir}/logs/functional_annotation.stderr"
 // Logging verbosity for some data upload processes
 loglevel = "info"
 // Uncomment and put your mail if your setup allows sending emails
 //email = "yourmail@yourdomain"
 // Uncomment lines below to skip those analyses
 //skip_cdSearch = true
 //skip_sigtarp  = true
}
